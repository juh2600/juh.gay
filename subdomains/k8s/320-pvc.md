---
title: 320-pvc
date: 2024-06-16
authors:
  - juh
prev: 310-namespace
next: 330-configmap
---
> [!file]+ 20-pvc.yaml
> ```yaml
> apiVersion: v1
> kind: PersistentVolumeClaim
> metadata:
>   name: smp-164-pvc
>   namespace: mcd
> spec:
>   accessModes:
>     - ReadWriteOnce
>   storageClassName: longhorn
>   resources:
>     requests:
>       storage: 5Gi
> ```

Disk storage in k8s is broken up into two halves: Persistent Volumes (PV), and Persistent Volume Claims (PVC). A PV is a chunk of storage. A PVC is a request for a chunk of storage. The storage rabbit hole is deep and wide and historied, and I have only looked at one corner of it, and it did what I need so it'll be a while before I look any further.

We'll be using Longhorn as our storage backend. Installing Longhorn is currently out of scope, but I might add it in later. I don't know if this is a Longhorn thing or a "dynamically provisioned storage" thing or an everywhere thing, but it seems we don't have to manually create PVs at all, just PVCs. In other words, we just ask for a chunk of storage and give it a name, and Longhorn magically handles finding disk space and setting it up for us.

We create this PVC within the `mcd` namespace, with the name `smp-164-pvc` which we'll use to mount this volume later, in our Deployment. The name isn't special, I just chose it to identify it from other volumes should I decide to spin up more servers in this namespace later.

The `accessModes` field determines the scope of pods that can access the volume simultaneously, as well as whether they can write to the volume. More on this can be found in the [k8s docs](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes).

The `storageClassName` field tells k8s...something about how to get ahold of the chunk of storage we're requesting. Longhorn provides the `longhorn` storage class, so we don't have to define one ourselves. It also provides `longhorn-static` I think, which sounds like the same thing but with dynamic provisioning disabled? I haven't tried it.

Because the `longhorn` storage class supports dynamic provisioning and volume resizing, we can [resize volumes](https://longhorn.io/docs/1.6.2/nodes-and-volumes/volumes/expansion/) after they've been used. At the moment, it looks like we need to stop using them in order for the resize to actually take place, which is reasonable enough.